{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tabula\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch PDF links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23s running time\n",
    "headers = {\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Referer': 'https://pdaandacollo.teck.com/',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',\n",
    "}\n",
    "\n",
    "response = requests.get('https://pdaandacollo.teck.com/services/api/DirectoryBrowser',headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = response.json()\n",
    "\n",
    "branch_acierto = root[14] # Registro Acierto de Tronadura Teck CDA\n",
    "\n",
    "base_url = 'https://pdaandacollo.teck.com/services/api/FileDownload/?filePath=\\\\'\n",
    "years = ['2023','2024']\n",
    "months_2023 = ['08. August','09. Septiembre','10. Octubre','11. Noviembre','12. Diciembre']\n",
    "\n",
    "url_pdfs = [\n",
    "    base_url + tronadura['Path'].replace(' ', '%20')\n",
    "    for year in branch_acierto['Nodes'] if year['Name'] in years\n",
    "    for month in year['Nodes']\n",
    "    if (year['Name'] == '2024' or (year['Name'] == '2023' and month['Name'] in months_2023))\n",
    "    for tronadura in month['Nodes']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert PDF to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5m 10s running time\n",
    "tables = []\n",
    "\n",
    "for url_pdf in url_pdfs:\n",
    "\n",
    "    # print(url_pdf)\n",
    "    \n",
    "    table = tabula.read_pdf(url_pdf, pages=1, multiple_tables=True)[-1]\n",
    "\n",
    "    table.insert(0, 'Date', url_pdf.replace('%20','')[-14:-4])\n",
    "    table.insert(0, 'URL', url_pdf) \n",
    "\n",
    "    tables.append(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate and Clean Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_clean = []\n",
    "\n",
    "for table in tables:\n",
    "    table.ffill(inplace=True)\n",
    "    # table[table['Unnamed: 2'].str.contains(r'\\d', na=False)]\n",
    "    table = table.iloc[5:,:7].dropna()\n",
    "    tables_clean.append(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw tables concatenated\n",
    "tables_concatenated = pd.concat(tables_clean)\n",
    "\n",
    "# reset index\n",
    "tables_concatenated.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# filter irrelevant rows\n",
    "tables_concatenated = tables_concatenated[~tables_concatenated['Unnamed: 0'].str.contains('N°')]\n",
    "\n",
    "# delete duplicates\n",
    "tables_concatenated.drop_duplicates(subset=['Date','Unnamed: 1','Unnamed: 2','Unnamed: 3'], inplace=True)\n",
    "\n",
    "# filter out rows that do not have ':' twice in row\n",
    "mask = tables_concatenated.map(lambda x: str(x).count(':'))\n",
    "row_sums = mask.sum(axis=1)\n",
    "filtered_df = tables_concatenated[row_sums >= 2]\n",
    "\n",
    "# New Column: Hora de Ejecucion\n",
    "filtered_df['all_columns_joined'] = filtered_df.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "pattern = r'\\b(\\d{1,2}:\\d{1,2})\\b'\n",
    "filtered_df['Hora de ejecución'] = filtered_df['all_columns_joined'].str.extractall(pattern).groupby(level=0).last()\n",
    "\n",
    "# rename column name\n",
    "filtered_df.rename({\n",
    "    'Unnamed: 1':'Fase, banco, y malla programada',\n",
    "    'Unnamed: 2':'Estado / Motivo de suspensión'\n",
    "    }, axis=1, inplace=True)\n",
    "\n",
    "# replace dots with a dash for Date column\n",
    "filtered_df['Date'] = filtered_df['Date'].str.replace('.', '-').copy()\n",
    "\n",
    "# select columns\n",
    "filtered_df = filtered_df[['Date','Fase, banco, y malla programada','Estado / Motivo de suspensión','Hora de ejecución','URL']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save table as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('pdaandacollo-teck.csv', encoding='iso-8859-1', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
